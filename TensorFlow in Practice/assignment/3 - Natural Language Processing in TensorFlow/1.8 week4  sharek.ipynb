{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "66\n",
      "8\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['in'])\n",
    "print(tokenizer.word_index['the'])\n",
    "print(tokenizer.word_index['town'])\n",
    "print(tokenizer.word_index['of'])\n",
    "print(tokenizer.word_index['athy'])\n",
    "print(tokenizer.word_index['one'])\n",
    "print(tokenizer.word_index['jeremy'])\n",
    "print(tokenizer.word_index['lanigan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  4  2 66  8 67 68 69]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(xs[6])\n",
    "print(ys[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples\n",
      "Epoch 1/500\n",
      "453/453 [==============================] - 3s 6ms/sample - loss: 5.5688 - accuracy: 0.0088\n",
      "Epoch 2/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 5.5474 - accuracy: 0.0442\n",
      "Epoch 3/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 5.5007 - accuracy: 0.0265\n",
      "Epoch 4/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 5.3640 - accuracy: 0.0265\n",
      "Epoch 5/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 5.1543 - accuracy: 0.0375\n",
      "Epoch 6/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 5.0690 - accuracy: 0.0574\n",
      "Epoch 7/500\n",
      "453/453 [==============================] - 0s 219us/sample - loss: 5.0260 - accuracy: 0.0728\n",
      "Epoch 8/500\n",
      "453/453 [==============================] - 0s 209us/sample - loss: 4.9965 - accuracy: 0.0508\n",
      "Epoch 9/500\n",
      "453/453 [==============================] - 0s 214us/sample - loss: 4.9674 - accuracy: 0.0552\n",
      "Epoch 10/500\n",
      "453/453 [==============================] - 0s 204us/sample - loss: 4.9328 - accuracy: 0.0728\n",
      "Epoch 11/500\n",
      "453/453 [==============================] - 0s 216us/sample - loss: 4.8995 - accuracy: 0.0596\n",
      "Epoch 12/500\n",
      "453/453 [==============================] - 0s 214us/sample - loss: 4.8587 - accuracy: 0.0574\n",
      "Epoch 13/500\n",
      "453/453 [==============================] - 0s 206us/sample - loss: 4.8132 - accuracy: 0.0662\n",
      "Epoch 14/500\n",
      "453/453 [==============================] - 0s 223us/sample - loss: 4.7583 - accuracy: 0.0795\n",
      "Epoch 15/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 4.6966 - accuracy: 0.0751\n",
      "Epoch 16/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 4.6273 - accuracy: 0.0861\n",
      "Epoch 17/500\n",
      "453/453 [==============================] - 0s 215us/sample - loss: 4.5612 - accuracy: 0.0993\n",
      "Epoch 18/500\n",
      "453/453 [==============================] - 0s 202us/sample - loss: 4.4997 - accuracy: 0.1170\n",
      "Epoch 19/500\n",
      "453/453 [==============================] - 0s 199us/sample - loss: 4.4399 - accuracy: 0.1258\n",
      "Epoch 20/500\n",
      "453/453 [==============================] - 0s 216us/sample - loss: 4.3726 - accuracy: 0.1347\n",
      "Epoch 21/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 4.3230 - accuracy: 0.1457\n",
      "Epoch 22/500\n",
      "453/453 [==============================] - 0s 219us/sample - loss: 4.2615 - accuracy: 0.1479\n",
      "Epoch 23/500\n",
      "453/453 [==============================] - 0s 218us/sample - loss: 4.2103 - accuracy: 0.1479\n",
      "Epoch 24/500\n",
      "453/453 [==============================] - 0s 217us/sample - loss: 4.1504 - accuracy: 0.1634\n",
      "Epoch 25/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 4.1159 - accuracy: 0.1501\n",
      "Epoch 26/500\n",
      "453/453 [==============================] - 0s 272us/sample - loss: 4.0656 - accuracy: 0.1766\n",
      "Epoch 27/500\n",
      "453/453 [==============================] - 0s 272us/sample - loss: 4.0137 - accuracy: 0.1744\n",
      "Epoch 28/500\n",
      "453/453 [==============================] - 0s 270us/sample - loss: 3.9739 - accuracy: 0.1898\n",
      "Epoch 29/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 3.9210 - accuracy: 0.1876\n",
      "Epoch 30/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 3.8689 - accuracy: 0.2141\n",
      "Epoch 31/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 3.8226 - accuracy: 0.2141\n",
      "Epoch 32/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 3.7797 - accuracy: 0.2119\n",
      "Epoch 33/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 3.7315 - accuracy: 0.2384\n",
      "Epoch 34/500\n",
      "453/453 [==============================] - 0s 263us/sample - loss: 3.6876 - accuracy: 0.2340\n",
      "Epoch 35/500\n",
      "453/453 [==============================] - 0s 319us/sample - loss: 3.6451 - accuracy: 0.2583\n",
      "Epoch 36/500\n",
      "453/453 [==============================] - 0s 323us/sample - loss: 3.6039 - accuracy: 0.2671\n",
      "Epoch 37/500\n",
      "453/453 [==============================] - 0s 265us/sample - loss: 3.5726 - accuracy: 0.2737\n",
      "Epoch 38/500\n",
      "453/453 [==============================] - 0s 289us/sample - loss: 3.5399 - accuracy: 0.2848\n",
      "Epoch 39/500\n",
      "453/453 [==============================] - 0s 299us/sample - loss: 3.5116 - accuracy: 0.3024\n",
      "Epoch 40/500\n",
      "453/453 [==============================] - 0s 295us/sample - loss: 3.4745 - accuracy: 0.3113\n",
      "Epoch 41/500\n",
      "453/453 [==============================] - 0s 326us/sample - loss: 3.4322 - accuracy: 0.3201\n",
      "Epoch 42/500\n",
      "453/453 [==============================] - 0s 344us/sample - loss: 3.3737 - accuracy: 0.3245\n",
      "Epoch 43/500\n",
      "453/453 [==============================] - 0s 316us/sample - loss: 3.3389 - accuracy: 0.3400\n",
      "Epoch 44/500\n",
      "453/453 [==============================] - 0s 310us/sample - loss: 3.2932 - accuracy: 0.3554\n",
      "Epoch 45/500\n",
      "453/453 [==============================] - 0s 306us/sample - loss: 3.2582 - accuracy: 0.3554\n",
      "Epoch 46/500\n",
      "453/453 [==============================] - 0s 339us/sample - loss: 3.2224 - accuracy: 0.3753\n",
      "Epoch 47/500\n",
      "453/453 [==============================] - 0s 321us/sample - loss: 3.1917 - accuracy: 0.3753\n",
      "Epoch 48/500\n",
      "453/453 [==============================] - 0s 314us/sample - loss: 3.1478 - accuracy: 0.3819\n",
      "Epoch 49/500\n",
      "453/453 [==============================] - 0s 331us/sample - loss: 3.1019 - accuracy: 0.3929\n",
      "Epoch 50/500\n",
      "453/453 [==============================] - 0s 347us/sample - loss: 3.0668 - accuracy: 0.4062\n",
      "Epoch 51/500\n",
      "453/453 [==============================] - 0s 347us/sample - loss: 3.0387 - accuracy: 0.4062\n",
      "Epoch 52/500\n",
      "453/453 [==============================] - 0s 337us/sample - loss: 3.0112 - accuracy: 0.4305\n",
      "Epoch 53/500\n",
      "453/453 [==============================] - 0s 316us/sample - loss: 2.9791 - accuracy: 0.4172\n",
      "Epoch 54/500\n",
      "453/453 [==============================] - 0s 304us/sample - loss: 2.9410 - accuracy: 0.4238\n",
      "Epoch 55/500\n",
      "453/453 [==============================] - 0s 306us/sample - loss: 2.9214 - accuracy: 0.4194\n",
      "Epoch 56/500\n",
      "453/453 [==============================] - 0s 304us/sample - loss: 2.8877 - accuracy: 0.4393\n",
      "Epoch 57/500\n",
      "453/453 [==============================] - 0s 294us/sample - loss: 2.8541 - accuracy: 0.4459\n",
      "Epoch 58/500\n",
      "453/453 [==============================] - 0s 301us/sample - loss: 2.8086 - accuracy: 0.4570\n",
      "Epoch 59/500\n",
      "453/453 [==============================] - 0s 316us/sample - loss: 2.7747 - accuracy: 0.4658\n",
      "Epoch 60/500\n",
      "453/453 [==============================] - 0s 309us/sample - loss: 2.7436 - accuracy: 0.4879\n",
      "Epoch 61/500\n",
      "453/453 [==============================] - 0s 299us/sample - loss: 2.7091 - accuracy: 0.4923\n",
      "Epoch 62/500\n",
      "453/453 [==============================] - 0s 300us/sample - loss: 2.6885 - accuracy: 0.4967\n",
      "Epoch 63/500\n",
      "453/453 [==============================] - 0s 272us/sample - loss: 2.6546 - accuracy: 0.4857\n",
      "Epoch 64/500\n",
      "453/453 [==============================] - 0s 275us/sample - loss: 2.6211 - accuracy: 0.5254\n",
      "Epoch 65/500\n",
      "453/453 [==============================] - 0s 338us/sample - loss: 2.5979 - accuracy: 0.5099\n",
      "Epoch 66/500\n",
      "453/453 [==============================] - 0s 304us/sample - loss: 2.5758 - accuracy: 0.5254\n",
      "Epoch 67/500\n",
      "453/453 [==============================] - 0s 355us/sample - loss: 2.5457 - accuracy: 0.5320\n",
      "Epoch 68/500\n",
      "453/453 [==============================] - 0s 361us/sample - loss: 2.5131 - accuracy: 0.5453\n",
      "Epoch 69/500\n",
      "453/453 [==============================] - 0s 319us/sample - loss: 2.4907 - accuracy: 0.5541\n",
      "Epoch 70/500\n",
      "453/453 [==============================] - 0s 309us/sample - loss: 2.4807 - accuracy: 0.5320\n",
      "Epoch 71/500\n",
      "453/453 [==============================] - 0s 275us/sample - loss: 2.4416 - accuracy: 0.5519\n",
      "Epoch 72/500\n",
      "453/453 [==============================] - 0s 290us/sample - loss: 2.4657 - accuracy: 0.5453\n",
      "Epoch 73/500\n",
      "453/453 [==============================] - 0s 267us/sample - loss: 2.4260 - accuracy: 0.5585\n",
      "Epoch 74/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 2.4098 - accuracy: 0.5342\n",
      "Epoch 75/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 2.3689 - accuracy: 0.5585\n",
      "Epoch 76/500\n",
      "453/453 [==============================] - 0s 283us/sample - loss: 2.3399 - accuracy: 0.5651\n",
      "Epoch 77/500\n",
      "453/453 [==============================] - 0s 321us/sample - loss: 2.3236 - accuracy: 0.5673\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 284us/sample - loss: 2.2862 - accuracy: 0.5784\n",
      "Epoch 79/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 2.2662 - accuracy: 0.5673\n",
      "Epoch 80/500\n",
      "453/453 [==============================] - 0s 342us/sample - loss: 2.2276 - accuracy: 0.5916\n",
      "Epoch 81/500\n",
      "453/453 [==============================] - 0s 273us/sample - loss: 2.2119 - accuracy: 0.5916\n",
      "Epoch 82/500\n",
      "453/453 [==============================] - 0s 268us/sample - loss: 2.2062 - accuracy: 0.5872\n",
      "Epoch 83/500\n",
      "453/453 [==============================] - 0s 262us/sample - loss: 2.1704 - accuracy: 0.5960\n",
      "Epoch 84/500\n",
      "453/453 [==============================] - 0s 268us/sample - loss: 2.1357 - accuracy: 0.6004\n",
      "Epoch 85/500\n",
      "453/453 [==============================] - 0s 270us/sample - loss: 2.1186 - accuracy: 0.6004\n",
      "Epoch 86/500\n",
      "453/453 [==============================] - 0s 265us/sample - loss: 2.0922 - accuracy: 0.5982\n",
      "Epoch 87/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 2.0651 - accuracy: 0.6203\n",
      "Epoch 88/500\n",
      "453/453 [==============================] - 0s 248us/sample - loss: 2.0459 - accuracy: 0.6203\n",
      "Epoch 89/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 2.0218 - accuracy: 0.6269\n",
      "Epoch 90/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 2.0091 - accuracy: 0.6291\n",
      "Epoch 91/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 1.9871 - accuracy: 0.6424\n",
      "Epoch 92/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 1.9621 - accuracy: 0.6402\n",
      "Epoch 93/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 1.9433 - accuracy: 0.6512\n",
      "Epoch 94/500\n",
      "453/453 [==============================] - 0s 265us/sample - loss: 1.9211 - accuracy: 0.6534\n",
      "Epoch 95/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 1.9018 - accuracy: 0.6556\n",
      "Epoch 96/500\n",
      "453/453 [==============================] - 0s 261us/sample - loss: 1.9006 - accuracy: 0.6534\n",
      "Epoch 97/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 1.8791 - accuracy: 0.6645\n",
      "Epoch 98/500\n",
      "453/453 [==============================] - 0s 281us/sample - loss: 1.8584 - accuracy: 0.6645\n",
      "Epoch 99/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 1.8340 - accuracy: 0.6799\n",
      "Epoch 100/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 1.8106 - accuracy: 0.6799\n",
      "Epoch 101/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 1.7889 - accuracy: 0.6887\n",
      "Epoch 102/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 1.7821 - accuracy: 0.6821\n",
      "Epoch 103/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 1.7699 - accuracy: 0.6821\n",
      "Epoch 104/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 1.7482 - accuracy: 0.6954\n",
      "Epoch 105/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 1.7297 - accuracy: 0.6909\n",
      "Epoch 106/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 1.7057 - accuracy: 0.7108\n",
      "Epoch 107/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 1.6945 - accuracy: 0.7108\n",
      "Epoch 108/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 1.6702 - accuracy: 0.7196\n",
      "Epoch 109/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 1.6499 - accuracy: 0.7241\n",
      "Epoch 110/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 1.6328 - accuracy: 0.7263\n",
      "Epoch 111/500\n",
      "453/453 [==============================] - 0s 293us/sample - loss: 1.6168 - accuracy: 0.7263\n",
      "Epoch 112/500\n",
      "453/453 [==============================] - 0s 293us/sample - loss: 1.6021 - accuracy: 0.7351\n",
      "Epoch 113/500\n",
      "453/453 [==============================] - 0s 277us/sample - loss: 1.5852 - accuracy: 0.7329\n",
      "Epoch 114/500\n",
      "453/453 [==============================] - 0s 277us/sample - loss: 1.5718 - accuracy: 0.7351\n",
      "Epoch 115/500\n",
      "453/453 [==============================] - 0s 262us/sample - loss: 1.5972 - accuracy: 0.7307\n",
      "Epoch 116/500\n",
      "453/453 [==============================] - 0s 264us/sample - loss: 1.5854 - accuracy: 0.7329\n",
      "Epoch 117/500\n",
      "453/453 [==============================] - 0s 261us/sample - loss: 1.5581 - accuracy: 0.7395\n",
      "Epoch 118/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 1.5235 - accuracy: 0.7506\n",
      "Epoch 119/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 1.5053 - accuracy: 0.7417\n",
      "Epoch 120/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 1.4828 - accuracy: 0.7550\n",
      "Epoch 121/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 1.4702 - accuracy: 0.7572\n",
      "Epoch 122/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 1.4536 - accuracy: 0.7616\n",
      "Epoch 123/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 1.4414 - accuracy: 0.7704\n",
      "Epoch 124/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 1.4300 - accuracy: 0.7638\n",
      "Epoch 125/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 1.4098 - accuracy: 0.7815\n",
      "Epoch 126/500\n",
      "453/453 [==============================] - 0s 278us/sample - loss: 1.4084 - accuracy: 0.7704\n",
      "Epoch 127/500\n",
      "453/453 [==============================] - 0s 267us/sample - loss: 1.3915 - accuracy: 0.7726\n",
      "Epoch 128/500\n",
      "453/453 [==============================] - 0s 272us/sample - loss: 1.3854 - accuracy: 0.7704\n",
      "Epoch 129/500\n",
      "453/453 [==============================] - 0s 258us/sample - loss: 1.3858 - accuracy: 0.7748\n",
      "Epoch 130/500\n",
      "453/453 [==============================] - 0s 291us/sample - loss: 1.3738 - accuracy: 0.7770\n",
      "Epoch 131/500\n",
      "453/453 [==============================] - 0s 274us/sample - loss: 1.3661 - accuracy: 0.7682\n",
      "Epoch 132/500\n",
      "453/453 [==============================] - 0s 259us/sample - loss: 1.3318 - accuracy: 0.7770\n",
      "Epoch 133/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 1.3146 - accuracy: 0.7837\n",
      "Epoch 134/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 1.3005 - accuracy: 0.7969\n",
      "Epoch 135/500\n",
      "453/453 [==============================] - 0s 261us/sample - loss: 1.2821 - accuracy: 0.7925\n",
      "Epoch 136/500\n",
      "453/453 [==============================] - 0s 261us/sample - loss: 1.2629 - accuracy: 0.8079\n",
      "Epoch 137/500\n",
      "453/453 [==============================] - 0s 269us/sample - loss: 1.2526 - accuracy: 0.8146\n",
      "Epoch 138/500\n",
      "453/453 [==============================] - 0s 266us/sample - loss: 1.2370 - accuracy: 0.8190\n",
      "Epoch 139/500\n",
      "453/453 [==============================] - 0s 275us/sample - loss: 1.2261 - accuracy: 0.8234\n",
      "Epoch 140/500\n",
      "453/453 [==============================] - 0s 282us/sample - loss: 1.2140 - accuracy: 0.8278\n",
      "Epoch 141/500\n",
      "453/453 [==============================] - 0s 263us/sample - loss: 1.1974 - accuracy: 0.8300\n",
      "Epoch 142/500\n",
      "453/453 [==============================] - 0s 263us/sample - loss: 1.1850 - accuracy: 0.8300\n",
      "Epoch 143/500\n",
      "453/453 [==============================] - 0s 267us/sample - loss: 1.1711 - accuracy: 0.8366\n",
      "Epoch 144/500\n",
      "453/453 [==============================] - 0s 290us/sample - loss: 1.1604 - accuracy: 0.8366\n",
      "Epoch 145/500\n",
      "453/453 [==============================] - 0s 287us/sample - loss: 1.1546 - accuracy: 0.8477\n",
      "Epoch 146/500\n",
      "453/453 [==============================] - 0s 286us/sample - loss: 1.1382 - accuracy: 0.8322\n",
      "Epoch 147/500\n",
      "453/453 [==============================] - 0s 295us/sample - loss: 1.1255 - accuracy: 0.8433\n",
      "Epoch 148/500\n",
      "453/453 [==============================] - 0s 280us/sample - loss: 1.1129 - accuracy: 0.8433\n",
      "Epoch 149/500\n",
      "453/453 [==============================] - 0s 267us/sample - loss: 1.1044 - accuracy: 0.8455\n",
      "Epoch 150/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 1.0951 - accuracy: 0.8455\n",
      "Epoch 151/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 1.0859 - accuracy: 0.8499\n",
      "Epoch 152/500\n",
      "453/453 [==============================] - 0s 272us/sample - loss: 1.0806 - accuracy: 0.8521\n",
      "Epoch 153/500\n",
      "453/453 [==============================] - 0s 316us/sample - loss: 1.0633 - accuracy: 0.8521\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 278us/sample - loss: 1.0538 - accuracy: 0.8543\n",
      "Epoch 155/500\n",
      "453/453 [==============================] - 0s 313us/sample - loss: 1.0426 - accuracy: 0.8521\n",
      "Epoch 156/500\n",
      "453/453 [==============================] - 0s 301us/sample - loss: 1.0281 - accuracy: 0.8543\n",
      "Epoch 157/500\n",
      "453/453 [==============================] - 0s 272us/sample - loss: 1.0192 - accuracy: 0.8587\n",
      "Epoch 158/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 1.0194 - accuracy: 0.8477\n",
      "Epoch 159/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 1.0142 - accuracy: 0.8433\n",
      "Epoch 160/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 1.0207 - accuracy: 0.8543\n",
      "Epoch 161/500\n",
      "453/453 [==============================] - 0s 248us/sample - loss: 1.0090 - accuracy: 0.8587\n",
      "Epoch 162/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 0.9975 - accuracy: 0.8543\n",
      "Epoch 163/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.9883 - accuracy: 0.8631\n",
      "Epoch 164/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.9867 - accuracy: 0.8587\n",
      "Epoch 165/500\n",
      "453/453 [==============================] - 0s 289us/sample - loss: 0.9731 - accuracy: 0.8543\n",
      "Epoch 166/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.9688 - accuracy: 0.8631\n",
      "Epoch 167/500\n",
      "453/453 [==============================] - 0s 267us/sample - loss: 0.9767 - accuracy: 0.8499\n",
      "Epoch 168/500\n",
      "453/453 [==============================] - 0s 300us/sample - loss: 0.9559 - accuracy: 0.8609\n",
      "Epoch 169/500\n",
      "453/453 [==============================] - 0s 300us/sample - loss: 0.9403 - accuracy: 0.8675\n",
      "Epoch 170/500\n",
      "453/453 [==============================] - 0s 265us/sample - loss: 0.9179 - accuracy: 0.8653\n",
      "Epoch 171/500\n",
      "453/453 [==============================] - 0s 284us/sample - loss: 0.9099 - accuracy: 0.8742\n",
      "Epoch 172/500\n",
      "453/453 [==============================] - 0s 324us/sample - loss: 0.9045 - accuracy: 0.8786\n",
      "Epoch 173/500\n",
      "453/453 [==============================] - 0s 300us/sample - loss: 0.8927 - accuracy: 0.8808\n",
      "Epoch 174/500\n",
      "453/453 [==============================] - 0s 325us/sample - loss: 0.8736 - accuracy: 0.8874\n",
      "Epoch 175/500\n",
      "453/453 [==============================] - 0s 310us/sample - loss: 0.8718 - accuracy: 0.8852\n",
      "Epoch 176/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 0.8774 - accuracy: 0.8808\n",
      "Epoch 177/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.8597 - accuracy: 0.8962\n",
      "Epoch 178/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 0.8484 - accuracy: 0.8962\n",
      "Epoch 179/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 0.8379 - accuracy: 0.8962\n",
      "Epoch 180/500\n",
      "453/453 [==============================] - 0s 278us/sample - loss: 0.8285 - accuracy: 0.8962\n",
      "Epoch 181/500\n",
      "453/453 [==============================] - 0s 261us/sample - loss: 0.8174 - accuracy: 0.8962\n",
      "Epoch 182/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 0.8066 - accuracy: 0.9007\n",
      "Epoch 183/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.7991 - accuracy: 0.9007\n",
      "Epoch 184/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.7913 - accuracy: 0.8985\n",
      "Epoch 185/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 0.7836 - accuracy: 0.9051\n",
      "Epoch 186/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.7758 - accuracy: 0.9051\n",
      "Epoch 187/500\n",
      "453/453 [==============================] - 0s 260us/sample - loss: 0.7710 - accuracy: 0.8985\n",
      "Epoch 188/500\n",
      "453/453 [==============================] - 0s 300us/sample - loss: 0.7661 - accuracy: 0.9007\n",
      "Epoch 189/500\n",
      "453/453 [==============================] - 0s 323us/sample - loss: 0.7624 - accuracy: 0.9007\n",
      "Epoch 190/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.7553 - accuracy: 0.8962\n",
      "Epoch 191/500\n",
      "453/453 [==============================] - 0s 302us/sample - loss: 0.7536 - accuracy: 0.8962\n",
      "Epoch 192/500\n",
      "453/453 [==============================] - 0s 335us/sample - loss: 0.7387 - accuracy: 0.9029\n",
      "Epoch 193/500\n",
      "453/453 [==============================] - 0s 320us/sample - loss: 0.7303 - accuracy: 0.9029\n",
      "Epoch 194/500\n",
      "453/453 [==============================] - 0s 315us/sample - loss: 0.7253 - accuracy: 0.9007\n",
      "Epoch 195/500\n",
      "453/453 [==============================] - 0s 325us/sample - loss: 0.7370 - accuracy: 0.9007\n",
      "Epoch 196/500\n",
      "453/453 [==============================] - 0s 338us/sample - loss: 0.7528 - accuracy: 0.8985\n",
      "Epoch 197/500\n",
      "453/453 [==============================] - 0s 289us/sample - loss: 0.7750 - accuracy: 0.8830\n",
      "Epoch 198/500\n",
      "453/453 [==============================] - 0s 280us/sample - loss: 0.7571 - accuracy: 0.8852\n",
      "Epoch 199/500\n",
      "453/453 [==============================] - 0s 325us/sample - loss: 0.7438 - accuracy: 0.8985\n",
      "Epoch 200/500\n",
      "453/453 [==============================] - 0s 264us/sample - loss: 0.7249 - accuracy: 0.8962\n",
      "Epoch 201/500\n",
      "453/453 [==============================] - 0s 279us/sample - loss: 0.7039 - accuracy: 0.9051\n",
      "Epoch 202/500\n",
      "453/453 [==============================] - 0s 313us/sample - loss: 0.6886 - accuracy: 0.9095\n",
      "Epoch 203/500\n",
      "453/453 [==============================] - 0s 302us/sample - loss: 0.6818 - accuracy: 0.9051\n",
      "Epoch 204/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.6802 - accuracy: 0.9095\n",
      "Epoch 205/500\n",
      "453/453 [==============================] - 0s 274us/sample - loss: 0.6750 - accuracy: 0.9051\n",
      "Epoch 206/500\n",
      "453/453 [==============================] - 0s 337us/sample - loss: 0.6643 - accuracy: 0.9117\n",
      "Epoch 207/500\n",
      "453/453 [==============================] - 0s 359us/sample - loss: 0.6584 - accuracy: 0.9139\n",
      "Epoch 208/500\n",
      "453/453 [==============================] - 0s 337us/sample - loss: 0.6518 - accuracy: 0.9095\n",
      "Epoch 209/500\n",
      "453/453 [==============================] - 0s 339us/sample - loss: 0.6429 - accuracy: 0.9139\n",
      "Epoch 210/500\n",
      "453/453 [==============================] - 0s 340us/sample - loss: 0.6340 - accuracy: 0.9161\n",
      "Epoch 211/500\n",
      "453/453 [==============================] - 0s 291us/sample - loss: 0.6267 - accuracy: 0.9139\n",
      "Epoch 212/500\n",
      "453/453 [==============================] - 0s 309us/sample - loss: 0.6204 - accuracy: 0.9183\n",
      "Epoch 213/500\n",
      "453/453 [==============================] - 0s 342us/sample - loss: 0.6153 - accuracy: 0.9183\n",
      "Epoch 214/500\n",
      "453/453 [==============================] - 0s 340us/sample - loss: 0.6086 - accuracy: 0.9183\n",
      "Epoch 215/500\n",
      "453/453 [==============================] - 0s 374us/sample - loss: 0.6030 - accuracy: 0.9205\n",
      "Epoch 216/500\n",
      "453/453 [==============================] - 0s 302us/sample - loss: 0.5987 - accuracy: 0.9161\n",
      "Epoch 217/500\n",
      "453/453 [==============================] - 0s 327us/sample - loss: 0.5923 - accuracy: 0.9205\n",
      "Epoch 218/500\n",
      "453/453 [==============================] - 0s 321us/sample - loss: 0.5943 - accuracy: 0.9161\n",
      "Epoch 219/500\n",
      "453/453 [==============================] - 0s 295us/sample - loss: 0.5950 - accuracy: 0.9095\n",
      "Epoch 220/500\n",
      "453/453 [==============================] - 0s 326us/sample - loss: 0.5840 - accuracy: 0.9161\n",
      "Epoch 221/500\n",
      "453/453 [==============================] - 0s 268us/sample - loss: 0.5758 - accuracy: 0.9161\n",
      "Epoch 222/500\n",
      "453/453 [==============================] - 0s 301us/sample - loss: 0.5702 - accuracy: 0.9183\n",
      "Epoch 223/500\n",
      "453/453 [==============================] - 0s 313us/sample - loss: 0.5706 - accuracy: 0.9161\n",
      "Epoch 224/500\n",
      "453/453 [==============================] - 0s 323us/sample - loss: 0.5645 - accuracy: 0.9139\n",
      "Epoch 225/500\n",
      "453/453 [==============================] - 0s 285us/sample - loss: 0.5573 - accuracy: 0.9183\n",
      "Epoch 226/500\n",
      "453/453 [==============================] - 0s 263us/sample - loss: 0.5514 - accuracy: 0.9205\n",
      "Epoch 227/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 0.5467 - accuracy: 0.9227\n",
      "Epoch 228/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 0.5442 - accuracy: 0.9249\n",
      "Epoch 229/500\n",
      "453/453 [==============================] - 0s 269us/sample - loss: 0.5431 - accuracy: 0.9183\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 277us/sample - loss: 0.5359 - accuracy: 0.9249\n",
      "Epoch 231/500\n",
      "453/453 [==============================] - 0s 260us/sample - loss: 0.5312 - accuracy: 0.9272\n",
      "Epoch 232/500\n",
      "453/453 [==============================] - 0s 297us/sample - loss: 0.5282 - accuracy: 0.9294\n",
      "Epoch 233/500\n",
      "453/453 [==============================] - 0s 311us/sample - loss: 0.5252 - accuracy: 0.9272\n",
      "Epoch 234/500\n",
      "453/453 [==============================] - 0s 327us/sample - loss: 0.5183 - accuracy: 0.9249\n",
      "Epoch 235/500\n",
      "453/453 [==============================] - 0s 346us/sample - loss: 0.5131 - accuracy: 0.9249\n",
      "Epoch 236/500\n",
      "453/453 [==============================] - 0s 308us/sample - loss: 0.5094 - accuracy: 0.9227\n",
      "Epoch 237/500\n",
      "453/453 [==============================] - 0s 305us/sample - loss: 0.5044 - accuracy: 0.9227\n",
      "Epoch 238/500\n",
      "453/453 [==============================] - 0s 331us/sample - loss: 0.5027 - accuracy: 0.9205\n",
      "Epoch 239/500\n",
      "453/453 [==============================] - 0s 318us/sample - loss: 0.5004 - accuracy: 0.9272\n",
      "Epoch 240/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.4971 - accuracy: 0.9294\n",
      "Epoch 241/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.4942 - accuracy: 0.9272\n",
      "Epoch 242/500\n",
      "453/453 [==============================] - 0s 333us/sample - loss: 0.4927 - accuracy: 0.9227\n",
      "Epoch 243/500\n",
      "453/453 [==============================] - 0s 336us/sample - loss: 0.5052 - accuracy: 0.9272\n",
      "Epoch 244/500\n",
      "453/453 [==============================] - 0s 284us/sample - loss: 0.5102 - accuracy: 0.9183\n",
      "Epoch 245/500\n",
      "453/453 [==============================] - 0s 313us/sample - loss: 0.5096 - accuracy: 0.9249\n",
      "Epoch 246/500\n",
      "453/453 [==============================] - 0s 298us/sample - loss: 0.5006 - accuracy: 0.9227\n",
      "Epoch 247/500\n",
      "453/453 [==============================] - 0s 310us/sample - loss: 0.5041 - accuracy: 0.9227\n",
      "Epoch 248/500\n",
      "453/453 [==============================] - 0s 263us/sample - loss: 0.4974 - accuracy: 0.9272\n",
      "Epoch 249/500\n",
      "453/453 [==============================] - 0s 262us/sample - loss: 0.4776 - accuracy: 0.9316\n",
      "Epoch 250/500\n",
      "453/453 [==============================] - 0s 259us/sample - loss: 0.4723 - accuracy: 0.9294\n",
      "Epoch 251/500\n",
      "453/453 [==============================] - 0s 264us/sample - loss: 0.4641 - accuracy: 0.9294\n",
      "Epoch 252/500\n",
      "453/453 [==============================] - 0s 278us/sample - loss: 0.4620 - accuracy: 0.9316\n",
      "Epoch 253/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.4563 - accuracy: 0.9294\n",
      "Epoch 254/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.4512 - accuracy: 0.9272\n",
      "Epoch 255/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 0.4465 - accuracy: 0.9294\n",
      "Epoch 256/500\n",
      "453/453 [==============================] - 0s 269us/sample - loss: 0.4424 - accuracy: 0.9338\n",
      "Epoch 257/500\n",
      "453/453 [==============================] - 0s 271us/sample - loss: 0.4385 - accuracy: 0.9294\n",
      "Epoch 258/500\n",
      "453/453 [==============================] - 0s 273us/sample - loss: 0.4353 - accuracy: 0.9338\n",
      "Epoch 259/500\n",
      "453/453 [==============================] - 0s 263us/sample - loss: 0.4318 - accuracy: 0.9338\n",
      "Epoch 260/500\n",
      "453/453 [==============================] - 0s 267us/sample - loss: 0.4280 - accuracy: 0.9360\n",
      "Epoch 261/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.4249 - accuracy: 0.9272\n",
      "Epoch 262/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 0.4220 - accuracy: 0.9316\n",
      "Epoch 263/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.4213 - accuracy: 0.9294\n",
      "Epoch 264/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.4181 - accuracy: 0.9360\n",
      "Epoch 265/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 0.4166 - accuracy: 0.9294\n",
      "Epoch 266/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.4138 - accuracy: 0.9316\n",
      "Epoch 267/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.4085 - accuracy: 0.9316\n",
      "Epoch 268/500\n",
      "453/453 [==============================] - 0s 261us/sample - loss: 0.4062 - accuracy: 0.9316\n",
      "Epoch 269/500\n",
      "453/453 [==============================] - 0s 248us/sample - loss: 0.4022 - accuracy: 0.9360\n",
      "Epoch 270/500\n",
      "453/453 [==============================] - 0s 266us/sample - loss: 0.3994 - accuracy: 0.9316\n",
      "Epoch 271/500\n",
      "453/453 [==============================] - 0s 275us/sample - loss: 0.3960 - accuracy: 0.9360\n",
      "Epoch 272/500\n",
      "453/453 [==============================] - 0s 260us/sample - loss: 0.3924 - accuracy: 0.9382\n",
      "Epoch 273/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 0.3877 - accuracy: 0.9382\n",
      "Epoch 274/500\n",
      "453/453 [==============================] - 0s 280us/sample - loss: 0.3838 - accuracy: 0.9404\n",
      "Epoch 275/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 0.3817 - accuracy: 0.9426\n",
      "Epoch 276/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.3806 - accuracy: 0.9404\n",
      "Epoch 277/500\n",
      "453/453 [==============================] - 0s 288us/sample - loss: 0.3777 - accuracy: 0.9404\n",
      "Epoch 278/500\n",
      "453/453 [==============================] - 0s 343us/sample - loss: 0.3747 - accuracy: 0.9404\n",
      "Epoch 279/500\n",
      "453/453 [==============================] - 0s 327us/sample - loss: 0.3715 - accuracy: 0.9426\n",
      "Epoch 280/500\n",
      "453/453 [==============================] - 0s 305us/sample - loss: 0.3679 - accuracy: 0.9404\n",
      "Epoch 281/500\n",
      "453/453 [==============================] - 0s 283us/sample - loss: 0.3659 - accuracy: 0.9382\n",
      "Epoch 282/500\n",
      "453/453 [==============================] - 0s 296us/sample - loss: 0.3656 - accuracy: 0.9382 - loss: 0.3888 - accuracy: 0.\n",
      "Epoch 283/500\n",
      "453/453 [==============================] - 0s 325us/sample - loss: 0.3618 - accuracy: 0.9426\n",
      "Epoch 284/500\n",
      "453/453 [==============================] - 0s 300us/sample - loss: 0.3589 - accuracy: 0.9382\n",
      "Epoch 285/500\n",
      "453/453 [==============================] - 0s 352us/sample - loss: 0.3566 - accuracy: 0.9404\n",
      "Epoch 286/500\n",
      "453/453 [==============================] - 0s 322us/sample - loss: 0.3544 - accuracy: 0.9426\n",
      "Epoch 287/500\n",
      "453/453 [==============================] - 0s 297us/sample - loss: 0.3540 - accuracy: 0.9448\n",
      "Epoch 288/500\n",
      "453/453 [==============================] - 0s 332us/sample - loss: 0.3512 - accuracy: 0.9404 - loss: 0.3373 - accuracy: 0.\n",
      "Epoch 289/500\n",
      "453/453 [==============================] - 0s 322us/sample - loss: 0.3548 - accuracy: 0.9404\n",
      "Epoch 290/500\n",
      "453/453 [==============================] - 0s 335us/sample - loss: 0.3735 - accuracy: 0.9360\n",
      "Epoch 291/500\n",
      "453/453 [==============================] - 0s 341us/sample - loss: 0.4981 - accuracy: 0.9051\n",
      "Epoch 292/500\n",
      "453/453 [==============================] - 0s 280us/sample - loss: 0.4839 - accuracy: 0.9073\n",
      "Epoch 293/500\n",
      "453/453 [==============================] - 0s 290us/sample - loss: 0.4525 - accuracy: 0.9117\n",
      "Epoch 294/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 0.4117 - accuracy: 0.9272\n",
      "Epoch 295/500\n",
      "453/453 [==============================] - 0s 258us/sample - loss: 0.3763 - accuracy: 0.9382\n",
      "Epoch 296/500\n",
      "453/453 [==============================] - 0s 258us/sample - loss: 0.3707 - accuracy: 0.9338\n",
      "Epoch 297/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 0.3615 - accuracy: 0.9360\n",
      "Epoch 298/500\n",
      "453/453 [==============================] - 0s 259us/sample - loss: 0.3581 - accuracy: 0.9338\n",
      "Epoch 299/500\n",
      "453/453 [==============================] - 0s 261us/sample - loss: 0.3451 - accuracy: 0.9382\n",
      "Epoch 300/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 0.3422 - accuracy: 0.9382\n",
      "Epoch 301/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.3352 - accuracy: 0.9426\n",
      "Epoch 302/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.3364 - accuracy: 0.9404\n",
      "Epoch 303/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.3337 - accuracy: 0.9360\n",
      "Epoch 304/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.3277 - accuracy: 0.9404\n",
      "Epoch 305/500\n",
      "453/453 [==============================] - 0s 274us/sample - loss: 0.3237 - accuracy: 0.9404\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 262us/sample - loss: 0.3181 - accuracy: 0.9382\n",
      "Epoch 307/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.3153 - accuracy: 0.9338\n",
      "Epoch 308/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.3146 - accuracy: 0.9448\n",
      "Epoch 309/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.3108 - accuracy: 0.9448\n",
      "Epoch 310/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.3080 - accuracy: 0.9448\n",
      "Epoch 311/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.3059 - accuracy: 0.9426\n",
      "Epoch 312/500\n",
      "453/453 [==============================] - 0s 230us/sample - loss: 0.3035 - accuracy: 0.9470\n",
      "Epoch 313/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 0.3027 - accuracy: 0.9382\n",
      "Epoch 314/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.3001 - accuracy: 0.9426\n",
      "Epoch 315/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.2980 - accuracy: 0.9404\n",
      "Epoch 316/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.2967 - accuracy: 0.9426\n",
      "Epoch 317/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 0.2955 - accuracy: 0.9426\n",
      "Epoch 318/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 0.2935 - accuracy: 0.9404\n",
      "Epoch 319/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 0.2912 - accuracy: 0.9448\n",
      "Epoch 320/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 0.2904 - accuracy: 0.9426\n",
      "Epoch 321/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.2888 - accuracy: 0.9470\n",
      "Epoch 322/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 0.2864 - accuracy: 0.9448\n",
      "Epoch 323/500\n",
      "453/453 [==============================] - 0s 285us/sample - loss: 0.2840 - accuracy: 0.9492\n",
      "Epoch 324/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 0.2824 - accuracy: 0.9470\n",
      "Epoch 325/500\n",
      "453/453 [==============================] - 0s 268us/sample - loss: 0.2813 - accuracy: 0.9448\n",
      "Epoch 326/500\n",
      "453/453 [==============================] - 0s 272us/sample - loss: 0.2815 - accuracy: 0.9470\n",
      "Epoch 327/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 0.2786 - accuracy: 0.9470\n",
      "Epoch 328/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.2768 - accuracy: 0.9470\n",
      "Epoch 329/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 0.2746 - accuracy: 0.9448\n",
      "Epoch 330/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.2738 - accuracy: 0.9448\n",
      "Epoch 331/500\n",
      "453/453 [==============================] - 0s 299us/sample - loss: 0.2712 - accuracy: 0.9492\n",
      "Epoch 332/500\n",
      "453/453 [==============================] - 0s 287us/sample - loss: 0.2695 - accuracy: 0.9470\n",
      "Epoch 333/500\n",
      "453/453 [==============================] - 0s 292us/sample - loss: 0.2687 - accuracy: 0.9426\n",
      "Epoch 334/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 0.2673 - accuracy: 0.9492\n",
      "Epoch 335/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 0.2647 - accuracy: 0.9448\n",
      "Epoch 336/500\n",
      "453/453 [==============================] - 0s 274us/sample - loss: 0.2638 - accuracy: 0.9448\n",
      "Epoch 337/500\n",
      "453/453 [==============================] - 0s 284us/sample - loss: 0.2621 - accuracy: 0.9470\n",
      "Epoch 338/500\n",
      "453/453 [==============================] - 0s 293us/sample - loss: 0.2613 - accuracy: 0.9492\n",
      "Epoch 339/500\n",
      "453/453 [==============================] - 0s 260us/sample - loss: 0.2613 - accuracy: 0.9404\n",
      "Epoch 340/500\n",
      "453/453 [==============================] - 0s 267us/sample - loss: 0.2578 - accuracy: 0.9470\n",
      "Epoch 341/500\n",
      "453/453 [==============================] - 0s 289us/sample - loss: 0.2565 - accuracy: 0.9492\n",
      "Epoch 342/500\n",
      "453/453 [==============================] - 0s 310us/sample - loss: 0.2545 - accuracy: 0.9404\n",
      "Epoch 343/500\n",
      "453/453 [==============================] - 0s 282us/sample - loss: 0.2533 - accuracy: 0.9470\n",
      "Epoch 344/500\n",
      "453/453 [==============================] - 0s 292us/sample - loss: 0.2526 - accuracy: 0.9470\n",
      "Epoch 345/500\n",
      "453/453 [==============================] - 0s 286us/sample - loss: 0.2506 - accuracy: 0.9470\n",
      "Epoch 346/500\n",
      "453/453 [==============================] - 0s 277us/sample - loss: 0.2494 - accuracy: 0.9448\n",
      "Epoch 347/500\n",
      "453/453 [==============================] - 0s 258us/sample - loss: 0.2490 - accuracy: 0.9492\n",
      "Epoch 348/500\n",
      "453/453 [==============================] - 0s 266us/sample - loss: 0.2471 - accuracy: 0.9514\n",
      "Epoch 349/500\n",
      "453/453 [==============================] - 0s 267us/sample - loss: 0.2462 - accuracy: 0.9470\n",
      "Epoch 350/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 0.2447 - accuracy: 0.9426\n",
      "Epoch 351/500\n",
      "453/453 [==============================] - 0s 259us/sample - loss: 0.2443 - accuracy: 0.9492\n",
      "Epoch 352/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.2424 - accuracy: 0.9470\n",
      "Epoch 353/500\n",
      "453/453 [==============================] - 0s 263us/sample - loss: 0.2415 - accuracy: 0.9470\n",
      "Epoch 354/500\n",
      "453/453 [==============================] - 0s 262us/sample - loss: 0.2398 - accuracy: 0.9492\n",
      "Epoch 355/500\n",
      "453/453 [==============================] - 0s 262us/sample - loss: 0.2383 - accuracy: 0.9514\n",
      "Epoch 356/500\n",
      "453/453 [==============================] - 0s 259us/sample - loss: 0.2391 - accuracy: 0.9470\n",
      "Epoch 357/500\n",
      "453/453 [==============================] - 0s 269us/sample - loss: 0.2367 - accuracy: 0.9514\n",
      "Epoch 358/500\n",
      "453/453 [==============================] - 0s 265us/sample - loss: 0.2360 - accuracy: 0.9492\n",
      "Epoch 359/500\n",
      "453/453 [==============================] - 0s 272us/sample - loss: 0.2332 - accuracy: 0.9492\n",
      "Epoch 360/500\n",
      "453/453 [==============================] - 0s 283us/sample - loss: 0.2316 - accuracy: 0.9448\n",
      "Epoch 361/500\n",
      "453/453 [==============================] - 0s 287us/sample - loss: 0.2305 - accuracy: 0.9514\n",
      "Epoch 362/500\n",
      "453/453 [==============================] - 0s 290us/sample - loss: 0.2296 - accuracy: 0.9470\n",
      "Epoch 363/500\n",
      "453/453 [==============================] - 0s 302us/sample - loss: 0.2283 - accuracy: 0.9492\n",
      "Epoch 364/500\n",
      "453/453 [==============================] - 0s 324us/sample - loss: 0.2274 - accuracy: 0.9492\n",
      "Epoch 365/500\n",
      "453/453 [==============================] - 0s 333us/sample - loss: 0.2262 - accuracy: 0.9514\n",
      "Epoch 366/500\n",
      "453/453 [==============================] - 0s 325us/sample - loss: 0.2254 - accuracy: 0.9448\n",
      "Epoch 367/500\n",
      "453/453 [==============================] - 0s 292us/sample - loss: 0.2243 - accuracy: 0.9426\n",
      "Epoch 368/500\n",
      "453/453 [==============================] - 0s 323us/sample - loss: 0.2234 - accuracy: 0.9492\n",
      "Epoch 369/500\n",
      "453/453 [==============================] - 0s 266us/sample - loss: 0.2219 - accuracy: 0.9492\n",
      "Epoch 370/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 0.2220 - accuracy: 0.9426\n",
      "Epoch 371/500\n",
      "453/453 [==============================] - 0s 275us/sample - loss: 0.2192 - accuracy: 0.9492\n",
      "Epoch 372/500\n",
      "453/453 [==============================] - 0s 269us/sample - loss: 0.2182 - accuracy: 0.9470\n",
      "Epoch 373/500\n",
      "453/453 [==============================] - 0s 258us/sample - loss: 0.2179 - accuracy: 0.9492\n",
      "Epoch 374/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.2158 - accuracy: 0.9492\n",
      "Epoch 375/500\n",
      "453/453 [==============================] - 0s 254us/sample - loss: 0.2160 - accuracy: 0.9514\n",
      "Epoch 376/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 0.2142 - accuracy: 0.9470\n",
      "Epoch 377/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 0.2128 - accuracy: 0.9492\n",
      "Epoch 378/500\n",
      "453/453 [==============================] - 0s 264us/sample - loss: 0.2131 - accuracy: 0.9492\n",
      "Epoch 379/500\n",
      "453/453 [==============================] - 0s 322us/sample - loss: 0.2125 - accuracy: 0.9492\n",
      "Epoch 380/500\n",
      "453/453 [==============================] - 0s 259us/sample - loss: 0.2114 - accuracy: 0.9514\n",
      "Epoch 381/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 0.2096 - accuracy: 0.9492\n",
      "Epoch 382/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 252us/sample - loss: 0.2081 - accuracy: 0.9492\n",
      "Epoch 383/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.2069 - accuracy: 0.9470\n",
      "Epoch 384/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.2068 - accuracy: 0.9448\n",
      "Epoch 385/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.2053 - accuracy: 0.9470\n",
      "Epoch 386/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.2045 - accuracy: 0.9470\n",
      "Epoch 387/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.2028 - accuracy: 0.9448\n",
      "Epoch 388/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.2021 - accuracy: 0.9470\n",
      "Epoch 389/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.2017 - accuracy: 0.9426\n",
      "Epoch 390/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.2010 - accuracy: 0.9492\n",
      "Epoch 391/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 0.1994 - accuracy: 0.9492\n",
      "Epoch 392/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 0.1991 - accuracy: 0.9470\n",
      "Epoch 393/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.1982 - accuracy: 0.9492\n",
      "Epoch 394/500\n",
      "453/453 [==============================] - 0s 221us/sample - loss: 0.1977 - accuracy: 0.9470\n",
      "Epoch 395/500\n",
      "453/453 [==============================] - 0s 235us/sample - loss: 0.1993 - accuracy: 0.9448\n",
      "Epoch 396/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.1971 - accuracy: 0.9470\n",
      "Epoch 397/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 0.1946 - accuracy: 0.9470\n",
      "Epoch 398/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 0.1936 - accuracy: 0.9448\n",
      "Epoch 399/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 0.1925 - accuracy: 0.9492\n",
      "Epoch 400/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.1915 - accuracy: 0.9492\n",
      "Epoch 401/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.1911 - accuracy: 0.9492\n",
      "Epoch 402/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 0.1906 - accuracy: 0.9470\n",
      "Epoch 403/500\n",
      "453/453 [==============================] - 0s 228us/sample - loss: 0.1894 - accuracy: 0.9470\n",
      "Epoch 404/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.1875 - accuracy: 0.9470\n",
      "Epoch 405/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.1864 - accuracy: 0.9492\n",
      "Epoch 406/500\n",
      "453/453 [==============================] - 0s 232us/sample - loss: 0.1856 - accuracy: 0.9426\n",
      "Epoch 407/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 0.1858 - accuracy: 0.9492\n",
      "Epoch 408/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 0.1854 - accuracy: 0.9404\n",
      "Epoch 409/500\n",
      "453/453 [==============================] - 0s 259us/sample - loss: 0.1839 - accuracy: 0.9404\n",
      "Epoch 410/500\n",
      "453/453 [==============================] - 0s 259us/sample - loss: 0.1840 - accuracy: 0.9426\n",
      "Epoch 411/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 0.1829 - accuracy: 0.9492\n",
      "Epoch 412/500\n",
      "453/453 [==============================] - 0s 271us/sample - loss: 0.1818 - accuracy: 0.9514\n",
      "Epoch 413/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 0.1846 - accuracy: 0.9404\n",
      "Epoch 414/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.1804 - accuracy: 0.9492\n",
      "Epoch 415/500\n",
      "453/453 [==============================] - 0s 235us/sample - loss: 0.1814 - accuracy: 0.9470\n",
      "Epoch 416/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.1795 - accuracy: 0.9514\n",
      "Epoch 417/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.1994 - accuracy: 0.9404\n",
      "Epoch 418/500\n",
      "453/453 [==============================] - 0s 242us/sample - loss: 0.2030 - accuracy: 0.9426\n",
      "Epoch 419/500\n",
      "453/453 [==============================] - 0s 224us/sample - loss: 0.2080 - accuracy: 0.9492\n",
      "Epoch 420/500\n",
      "453/453 [==============================] - 0s 226us/sample - loss: 0.2706 - accuracy: 0.9249\n",
      "Epoch 421/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 0.2653 - accuracy: 0.9382\n",
      "Epoch 422/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 0.2723 - accuracy: 0.9205\n",
      "Epoch 423/500\n",
      "453/453 [==============================] - 0s 240us/sample - loss: 0.2642 - accuracy: 0.9272\n",
      "Epoch 424/500\n",
      "453/453 [==============================] - 0s 239us/sample - loss: 0.2506 - accuracy: 0.9338\n",
      "Epoch 425/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.2286 - accuracy: 0.9360\n",
      "Epoch 426/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 0.2175 - accuracy: 0.9404\n",
      "Epoch 427/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.2110 - accuracy: 0.9448\n",
      "Epoch 428/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 0.2741 - accuracy: 0.9161\n",
      "Epoch 429/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 0.2041 - accuracy: 0.9426\n",
      "Epoch 430/500\n",
      "453/453 [==============================] - 0s 229us/sample - loss: 0.1923 - accuracy: 0.9492\n",
      "Epoch 431/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.1829 - accuracy: 0.9470\n",
      "Epoch 432/500\n",
      "453/453 [==============================] - 0s 237us/sample - loss: 0.1782 - accuracy: 0.9470\n",
      "Epoch 433/500\n",
      "453/453 [==============================] - 0s 234us/sample - loss: 0.1742 - accuracy: 0.9470\n",
      "Epoch 434/500\n",
      "453/453 [==============================] - 0s 233us/sample - loss: 0.1729 - accuracy: 0.9492\n",
      "Epoch 435/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 0.1714 - accuracy: 0.9448\n",
      "Epoch 436/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 0.1714 - accuracy: 0.9492\n",
      "Epoch 437/500\n",
      "453/453 [==============================] - 0s 259us/sample - loss: 0.1693 - accuracy: 0.9514\n",
      "Epoch 438/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.1687 - accuracy: 0.9536\n",
      "Epoch 439/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 0.1673 - accuracy: 0.9492\n",
      "Epoch 440/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 0.1665 - accuracy: 0.9470\n",
      "Epoch 441/500\n",
      "453/453 [==============================] - 0s 256us/sample - loss: 0.1655 - accuracy: 0.9426\n",
      "Epoch 442/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 0.1652 - accuracy: 0.9426\n",
      "Epoch 443/500\n",
      "453/453 [==============================] - 0s 255us/sample - loss: 0.1691 - accuracy: 0.9404\n",
      "Epoch 444/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.1667 - accuracy: 0.9470\n",
      "Epoch 445/500\n",
      "453/453 [==============================] - 0s 258us/sample - loss: 0.1650 - accuracy: 0.9536\n",
      "Epoch 446/500\n",
      "453/453 [==============================] - 0s 243us/sample - loss: 0.1633 - accuracy: 0.9492\n",
      "Epoch 447/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.1624 - accuracy: 0.9492\n",
      "Epoch 448/500\n",
      "453/453 [==============================] - 0s 277us/sample - loss: 0.1615 - accuracy: 0.9492\n",
      "Epoch 449/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.1600 - accuracy: 0.9448\n",
      "Epoch 450/500\n",
      "453/453 [==============================] - 0s 258us/sample - loss: 0.1600 - accuracy: 0.9470\n",
      "Epoch 451/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 0.1583 - accuracy: 0.9470\n",
      "Epoch 452/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 0.1581 - accuracy: 0.9470\n",
      "Epoch 453/500\n",
      "453/453 [==============================] - 0s 244us/sample - loss: 0.1575 - accuracy: 0.9492\n",
      "Epoch 454/500\n",
      "453/453 [==============================] - 0s 257us/sample - loss: 0.1582 - accuracy: 0.9492\n",
      "Epoch 455/500\n",
      "453/453 [==============================] - 0s 252us/sample - loss: 0.1580 - accuracy: 0.9492\n",
      "Epoch 456/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 0.1572 - accuracy: 0.9426\n",
      "Epoch 457/500\n",
      "453/453 [==============================] - 0s 321us/sample - loss: 0.1563 - accuracy: 0.9536\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 294us/sample - loss: 0.1552 - accuracy: 0.9470\n",
      "Epoch 459/500\n",
      "453/453 [==============================] - 0s 288us/sample - loss: 0.1542 - accuracy: 0.9448\n",
      "Epoch 460/500\n",
      "453/453 [==============================] - 0s 303us/sample - loss: 0.1535 - accuracy: 0.9470\n",
      "Epoch 461/500\n",
      "453/453 [==============================] - 0s 347us/sample - loss: 0.1534 - accuracy: 0.9492\n",
      "Epoch 462/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.1572 - accuracy: 0.9514\n",
      "Epoch 463/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.1616 - accuracy: 0.9426\n",
      "Epoch 464/500\n",
      "453/453 [==============================] - 0s 248us/sample - loss: 0.1532 - accuracy: 0.9514\n",
      "Epoch 465/500\n",
      "453/453 [==============================] - 0s 251us/sample - loss: 0.1524 - accuracy: 0.9426\n",
      "Epoch 466/500\n",
      "453/453 [==============================] - 0s 250us/sample - loss: 0.1508 - accuracy: 0.9492\n",
      "Epoch 467/500\n",
      "453/453 [==============================] - 0s 245us/sample - loss: 0.1506 - accuracy: 0.9492\n",
      "Epoch 468/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 0.1506 - accuracy: 0.9470\n",
      "Epoch 469/500\n",
      "453/453 [==============================] - 0s 241us/sample - loss: 0.1495 - accuracy: 0.9492\n",
      "Epoch 470/500\n",
      "453/453 [==============================] - 0s 238us/sample - loss: 0.1512 - accuracy: 0.9514\n",
      "Epoch 471/500\n",
      "453/453 [==============================] - 0s 247us/sample - loss: 0.1512 - accuracy: 0.9492\n",
      "Epoch 472/500\n",
      "453/453 [==============================] - 0s 248us/sample - loss: 0.1496 - accuracy: 0.9536\n",
      "Epoch 473/500\n",
      "453/453 [==============================] - 0s 246us/sample - loss: 0.1489 - accuracy: 0.9536\n",
      "Epoch 474/500\n",
      "453/453 [==============================] - 0s 236us/sample - loss: 0.1473 - accuracy: 0.9470\n",
      "Epoch 475/500\n",
      "453/453 [==============================] - 0s 302us/sample - loss: 0.1469 - accuracy: 0.9470\n",
      "Epoch 476/500\n",
      "453/453 [==============================] - 0s 258us/sample - loss: 0.1468 - accuracy: 0.9514\n",
      "Epoch 477/500\n",
      "453/453 [==============================] - 0s 263us/sample - loss: 0.1463 - accuracy: 0.9492\n",
      "Epoch 478/500\n",
      "453/453 [==============================] - 0s 269us/sample - loss: 0.1452 - accuracy: 0.9536\n",
      "Epoch 479/500\n",
      "453/453 [==============================] - 0s 262us/sample - loss: 0.1454 - accuracy: 0.9492\n",
      "Epoch 480/500\n",
      "453/453 [==============================] - 0s 249us/sample - loss: 0.1446 - accuracy: 0.9536\n",
      "Epoch 481/500\n",
      "453/453 [==============================] - 0s 253us/sample - loss: 0.1450 - accuracy: 0.9448\n",
      "Epoch 482/500\n",
      "453/453 [==============================] - 0s 261us/sample - loss: 0.1438 - accuracy: 0.9514\n",
      "Epoch 483/500\n",
      "453/453 [==============================] - 0s 283us/sample - loss: 0.1448 - accuracy: 0.9470\n",
      "Epoch 484/500\n",
      "453/453 [==============================] - 0s 296us/sample - loss: 0.1431 - accuracy: 0.9514\n",
      "Epoch 485/500\n",
      "453/453 [==============================] - 0s 290us/sample - loss: 0.1433 - accuracy: 0.9514\n",
      "Epoch 486/500\n",
      "453/453 [==============================] - 0s 299us/sample - loss: 0.1422 - accuracy: 0.9514\n",
      "Epoch 487/500\n",
      "453/453 [==============================] - 0s 274us/sample - loss: 0.1425 - accuracy: 0.9514\n",
      "Epoch 488/500\n",
      "453/453 [==============================] - 0s 285us/sample - loss: 0.1421 - accuracy: 0.9448\n",
      "Epoch 489/500\n",
      "453/453 [==============================] - 0s 305us/sample - loss: 0.1419 - accuracy: 0.9448\n",
      "Epoch 490/500\n",
      "453/453 [==============================] - 0s 314us/sample - loss: 0.1414 - accuracy: 0.9470\n",
      "Epoch 491/500\n",
      "453/453 [==============================] - 0s 309us/sample - loss: 0.1404 - accuracy: 0.9514\n",
      "Epoch 492/500\n",
      "453/453 [==============================] - 0s 277us/sample - loss: 0.1403 - accuracy: 0.9514\n",
      "Epoch 493/500\n",
      "453/453 [==============================] - 0s 269us/sample - loss: 0.1392 - accuracy: 0.9514\n",
      "Epoch 494/500\n",
      "453/453 [==============================] - 0s 271us/sample - loss: 0.1391 - accuracy: 0.9514\n",
      "Epoch 495/500\n",
      "453/453 [==============================] - 0s 292us/sample - loss: 0.1389 - accuracy: 0.9492\n",
      "Epoch 496/500\n",
      "453/453 [==============================] - 0s 291us/sample - loss: 0.1387 - accuracy: 0.9470\n",
      "Epoch 497/500\n",
      "453/453 [==============================] - 0s 261us/sample - loss: 0.1395 - accuracy: 0.9492\n",
      "Epoch 498/500\n",
      "453/453 [==============================] - 0s 275us/sample - loss: 0.1425 - accuracy: 0.9470\n",
      "Epoch 499/500\n",
      "453/453 [==============================] - 0s 267us/sample - loss: 0.1455 - accuracy: 0.9470\n",
      "Epoch 500/500\n",
      "453/453 [==============================] - 0s 305us/sample - loss: 0.1452 - accuracy: 0.9514\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laurence went to dublin the chaneys of a catchers little hall hall strangled murther daughter daughter hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall hall\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Laurence went to dublin\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
